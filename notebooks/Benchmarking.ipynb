{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saket/anaconda3/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['imread']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext line_profiler\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyvirchow.deep_model.model import get_model\n",
    "#, predict_on_batch, predict_on_patch, slide_level_map\n",
    "from pyvirchow.io.operations import WSIReader\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from pyvirchow.morphology.mask import get_common_interior_polygons\n",
    "from pyvirchow.io.operations import get_annotation_polygons\n",
    "from pyvirchow.io.operations import poly2mask\n",
    "from pyvirchow.io.operations import translate_and_scale_polygon\n",
    "from pyvirchow.io.operations import WSIReader\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "\n",
    "from shapely.geometry import Point as shapelyPoint\n",
    "from shapely.geometry import Polygon as shapelyPolygon\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "def get_tiles_fast(batch_samples,\n",
    "                   patch_size=256,\n",
    "                   num_classes=2,\n",
    "                   convert_to_cat=True):\n",
    "    X_train = batch_samples.img_path.apply(lambda x: joblib.load(x)).tolist()\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = batch_samples.mask_path.apply(lambda x: joblib.load(x)).tolist()\n",
    "    return X_train, y_train\n",
    "\n",
    "def mask_to_categorical(y, num_classes=2, patch_size=256):\n",
    "    \"\"\"Convert binary mask to categorical array for Keras/TF.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: array\n",
    "       Input array\n",
    "    num_classes: int\n",
    "                 Number of classes (2)\n",
    "    patch_size: int\n",
    "                Original patch size\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    y_cat: array\n",
    "           Output array\n",
    "    \"\"\"\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    y_cat = to_categorical(\n",
    "        y, num_classes=num_classes).reshape(y.shape[0], patch_size, patch_size,\n",
    "                                            num_classes)\n",
    "    return y_cat\n",
    "\n",
    "\n",
    "def create_tumor_mask_from_tile(tile_x, tile_y, polygons, patch_size=256):\n",
    "    \"\"\"Create a patch_size x patch_size mask from tile_x,y coordinates\n",
    "    Parameters\n",
    "    ----------\n",
    "    tile_x, tile_y:  int\n",
    "    polygons: dict\n",
    "              ['normal', 'tumor'] with corresponding polygons\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask: array\n",
    "          patch_size x patch_size binary mask\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Initiate a zero mask\n",
    "    mask = np.zeros((patch_size, patch_size))\n",
    "    #patch_polygon = shapelyRectangle(tile_x, tile_y, patch_size, patch_size)\n",
    "    x_min = tile_x\n",
    "    y_min = tile_y\n",
    "    x_max = x_min + 256\n",
    "    y_max = y_min + 256\n",
    "    patch_polygon = shapelyPolygon([(x_min, y_min), (x_max, y_min),\n",
    "                                    (x_max, y_max), (x_min, y_max)])\n",
    "\n",
    "    # Is it overlapping any of the tumor polygons?\n",
    "    is_inside_tumor = [\n",
    "        patch_polygon.intersection(polygon.buffer(0))\n",
    "        for polygon in polygons['tumor']\n",
    "    ]\n",
    "\n",
    "    # the patch will always be inside just one annotated boundary\n",
    "    # which are assumed to be non-overlapping and hence we can just fetch\n",
    "    # the first sample\n",
    "    tumor_poly_index = None\n",
    "    tumor_poly_coords = None\n",
    "    for index, sample_intersection in enumerate(is_inside_tumor):\n",
    "        if sample_intersection.area > 0:\n",
    "            tumor_poly_index = index\n",
    "            if sample_intersection.geom_type == 'Polygon':\n",
    "                tumor_poly_coords = np.array(\n",
    "                    sample_intersection.exterior.coords)\n",
    "            elif sample_intersection.geom_type == 'MultiPolygon':\n",
    "                tumor_poly_coords = []\n",
    "                for p in sample_intersection:\n",
    "                    tumor_poly_coords += p.exterior.coords\n",
    "                tumor_poly_coords = np.array(tumor_poly_coords)\n",
    "            elif sample_intersection.geom_type == 'GeometryCollection':\n",
    "                tumor_poly_coords = []\n",
    "                for p in sample_intersection:\n",
    "                    if p.geom_type == 'LineString' or p.geom_type == 'Point':\n",
    "                        tumor_poly_coords += p.coords\n",
    "                    elif p.geom_type == 'Polygon':\n",
    "                        tumor_poly_coords += p.exterior.coords\n",
    "                    else:\n",
    "                        print('Found geom_type:{}'.format(p.geom_type))\n",
    "                        raise ValueError('')\n",
    "            else:\n",
    "                print('Found geom_type:{}'.format(\n",
    "                    sample_intersection.geom_type))\n",
    "                raise ValueError('')\n",
    "            break\n",
    "\n",
    "    if tumor_poly_index is None:\n",
    "        # No overlap with tumor so must return as is\n",
    "        return mask\n",
    "\n",
    "    # This path belongs to a tumor patch so set everything to one\n",
    "    # Set these coordinates to one\n",
    "\n",
    "    # Shift the tumor coordinates to tile_x, tile_y\n",
    "    tumor_poly_coords = tumor_poly_coords - np.array([tile_x, tile_y])\n",
    "    overlapping_tumor_poly = shapelyPolygon(tumor_poly_coords)\n",
    "    # Create a psuedo mask\n",
    "    psuedo_mask = poly2mask([overlapping_tumor_poly], (patch_size, patch_size))\n",
    "    # Add it to the original mask\n",
    "    mask = np.logical_or(mask, psuedo_mask)\n",
    "\n",
    "    # If its inside tumor does this tumor patch actually contain any normal patches?\n",
    "    tumor_poly = polygons['tumor'][tumor_poly_index]\n",
    "    normal_patches_inside_tumor = get_common_interior_polygons(\n",
    "        tumor_poly, polygons['normal'])\n",
    "\n",
    "    # For all the normal patches, ensure\n",
    "    # we set the mask to zero\n",
    "    for index in normal_patches_inside_tumor:\n",
    "        normal_poly = polygons['normal'][index]\n",
    "\n",
    "        # What is the intersection portion of this normal polygon\n",
    "        # with our patch of interest?\n",
    "        common_area = normal_poly.intersection(patch_polygon)\n",
    "        if not common_area.is_valid:\n",
    "            return mask\n",
    "        if common_area.geom_type == 'Polygon':\n",
    "            normal_poly_coords = np.array(\n",
    "                common_area.exterior.coords) - np.array([tile_x, tile_y])\n",
    "        elif common_area.geom_type == 'MultiPolygon':\n",
    "            normal_poly_coords = []\n",
    "            for p in common_area:\n",
    "                normal_poly_coords += p.exterior.coords\n",
    "            normal_poly_coords = np.array(normal_poly_coords) - np.array(\n",
    "                [tile_x, tile_y])\n",
    "        if common_area:\n",
    "            overlapping_normal_poly = shapelyPolygon(normal_poly_coords)\n",
    "            psuedo_mask = poly2mask([overlapping_normal_poly],\n",
    "                                    (patch_size, patch_size))\n",
    "            # Get coordinates wherever this is non zero\n",
    "            non_zero_coords = np.where(psuedo_mask > 0)\n",
    "            # Add set these explicitly to zero\n",
    "            mask[non_zero_coords] = 0\n",
    "    return mask\n",
    "\n",
    "def get_approx_tumor_mask(polygons,\n",
    "                          thumbnail_nrow,\n",
    "                          thumbnail_ncol,\n",
    "                          patch_size=256):\n",
    "    \"\"\"Indicate whether a particular tile overlaps with tumor annotation.\n",
    "\n",
    "    The method has an approx in its name, as the entire tile\n",
    "    might not be coming from a tumor annotated region as parts of\n",
    "    it might actually be normal. We just report\n",
    "    here if the patch overlaps with a tumor annotation. It might have\n",
    "    an overlap with a normal region as well, but that is filtered\n",
    "    in a later method so we don't worry about it here.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    polygons: dict\n",
    "              dict with keys ['normal', 'tumor']\n",
    "              as obtained from `get_annotation_polygons`\n",
    "    thumbnail_nrow: int\n",
    "                    Number of rows in the thumbnail image\n",
    "    thumbnail_ncol: int\n",
    "                    Number of columns in the thumbnail\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask: array\n",
    "          tumor mask\n",
    "    \"\"\"\n",
    "    scaled_tumor_polygons = []\n",
    "    for tpol in polygons['tumor']:\n",
    "        scaled = translate_and_scale_polygon(tpol, 0, 0, 1 / 256)\n",
    "        scaled_tumor_polygons.append(scaled)\n",
    "    polymasked = poly2mask(scaled_tumor_polygons,\n",
    "                           (thumbnail_nrow, thumbnail_ncol))\n",
    "    # Is any of the masked out points inside a normal annotated region?\n",
    "    poly_x, poly_y = np.where(polymasked > 0)\n",
    "    set_to_zero = []\n",
    "    for px, py in zip(poly_x, poly_y):\n",
    "        point = shapelyPoint(px, py)\n",
    "        for npol in polygons['normal']:\n",
    "            scaled = translate_and_scale_polygon(npol, 0, 0, 1 / 256)\n",
    "            pol = shapelyPolygon(scaled.get_xy())\n",
    "            if pol.contains(point):\n",
    "                set_to_zero.append((px, py))\n",
    "\n",
    "    if len(set_to_zero):\n",
    "        set_to_zero = np.array(set_to_zero)\n",
    "        polymasked[set_to_zero] = 0\n",
    "    return polymasked\n",
    "\n",
    "def get_all_patches_from_slide(slide_path,\n",
    "                               json_filepath=None,\n",
    "                               filter_non_tissue=True,\n",
    "                               patch_size=256,\n",
    "                               saveto=None):\n",
    "    \"\"\"Extract a dataframe of all patches\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    slide_path: string\n",
    "                Path to slide\n",
    "    json_filepath: string\n",
    "                   Path to annotation file\n",
    "    filter_non_tissue: bool\n",
    "                       Should remove tiles with no tissue?\n",
    "    saveto: string\n",
    "            Path to store output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tiles_df: pd.DataFrame\n",
    "              A dataframe with the following columns:\n",
    "                  slide_path - abs. path to slide\n",
    "                  uid - slide filename\n",
    "                  is_tissue - True/False\n",
    "                  is_tumor - True/False\n",
    "                  tile_loc - (row, col) coordinate of the tile\n",
    "\n",
    "    \"\"\"\n",
    "    with WSIReader(slide_path, 40) as slide:\n",
    "        thumbnail = slide.get_thumbnail(\n",
    "            (int(slide.dimensions[0] / patch_size),\n",
    "             int(slide.dimensions[1] / patch_size)))\n",
    "        thumbnail_nrow = int(slide.width / patch_size)\n",
    "        thumbnail_ncol = int(slide.height / patch_size)\n",
    "\n",
    "    thumbnail_grey = np.array(thumbnail.convert('L'))  # convert to grayscale\n",
    "\n",
    "    thresh = threshold_otsu(thumbnail_grey)\n",
    "    binary = thumbnail_grey > thresh\n",
    "\n",
    "    patches = pd.DataFrame(pd.DataFrame(binary).stack())\n",
    "    patches.loc[:, 'is_tissue'] = ~patches[0]\n",
    "    patches.drop(0, axis=1, inplace=True)\n",
    "\n",
    "    if json_filepath is not None:\n",
    "        polygons = get_annotation_polygons(json_filepath)\n",
    "        polymasked = get_approx_tumor_mask(polygons, thumbnail_nrow,\n",
    "                                           thumbnail_ncol)\n",
    "\n",
    "        patches_tumor = pd.DataFrame(pd.DataFrame(polymasked).stack())\n",
    "        patches_tumor['is_tumor'] = patches_tumor[0] > 0\n",
    "        patches_tumor.drop(0, axis=1, inplace=True)\n",
    "\n",
    "        patches = pd.concat([patches, patches_tumor], axis=1)\n",
    "\n",
    "    patches.loc[:, 'uid'] = os.path.basename(slide_path).replace('.tif', '')\n",
    "    patches.loc[:, 'slide_path'] = os.path.abspath(slide_path)\n",
    "    patches.loc[:, 'json_filepath'] = json_filepath\n",
    "    if filter_non_tissue:\n",
    "        patches = patches[patches.is_tissue ==\n",
    "                          True]  # remove patches with no tissue\n",
    "    patches['tile_loc'] = list(patches.index)\n",
    "    patches.reset_index(inplace=True, drop=True)\n",
    "    if saveto:\n",
    "        patches.to_csv(saveto, sep='\\t', index=False, header=True)\n",
    "    return patches\n",
    "\n",
    "def predict_on_batch(patches, model):\n",
    "    \"\"\"Predict pixel level probabilites of being a tumor of collection of patches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patches: array_like\n",
    "             A batch (list) of patches\n",
    "    model: Keras model\n",
    "           as obtained from get_model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prediction: array_like\n",
    "                patch_size x patch_size x 1  per-pixel tumor probability\n",
    "    \"\"\"\n",
    "    prediction = model.predict(patches)\n",
    "    prediction = prediction[:, :, :, 1]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def process_batch(args):\n",
    "    idx, model, batch_samples, batch_size = args\n",
    "    output_thumbnail_pred = None\n",
    "    X, _ = get_tiles(batch_samples)\n",
    "    if batch_samples.is_tissue.nunique(\n",
    "    ) == 1 and batch_samples.iloc[0].is_tissue == False:\n",
    "        # all patches in this row do not have tissue, skip them all\n",
    "        output_thumbnail_pred = np.zeros(batch_size, dtype=np.float32)\n",
    "\n",
    "    else:\n",
    "        # make predictions\n",
    "        preds = predict_on_batch(X, model)\n",
    "        output_thumbnail_pred = preds.mean(axis=(1, 2))\n",
    "    return idx, output_thumbnail_pred\n",
    "\n",
    "\n",
    "def slide_level_map(model, slide_path, batch_size=32, json_filepath=None):\n",
    "    all_samples = get_all_patches_from_slide(slide_path, json_filepath, False,\n",
    "                                             256)\n",
    "    all_samples = all_samples.sample(frac=0.01)\n",
    "    n_samples = len(all_samples.index)\n",
    "    all_batch_samples = []\n",
    "    for idx, offset in enumerate(list(range(0, n_samples, batch_size))):\n",
    "        all_batch_samples.append((idx , model, all_samples.iloc[offset:offset + batch_size], batch_size))\n",
    "    output_thumbnail_preds = []\n",
    "    output_thumbnail_idx = []\n",
    "    total = len(all_batch_samples)\n",
    "    idx, o = process_batch(all_batch_samples[0])\n",
    "    #print(idx)\n",
    "    #print(o)\n",
    "    #with Pool(processes=32) as p:\n",
    "    #    with tqdm(total=total) as pbar:\n",
    "    #for idx, result in (process_batch, all_batch_samples):\n",
    "    for batch in tqdm(all_batch_samples):\n",
    "        idx, result = process_batch(batch)\n",
    "        output_thumbnail_preds.append(result)\n",
    "        output_thumbnail_idx.append(idx)\n",
    "        #pbar.update()\n",
    "    output_thumbnail_idx = np.array(output_thumbnail_idx)\n",
    "    output_thumbnail_preds = np.array(output_thumbnail_preds)\n",
    "    output_thumbnail_preds = output_thumbnail_preds[output_thumbnail_idx]\n",
    "    return output_thumbnail_preds\n",
    "\n",
    "def get_tiles(batch_samples,\n",
    "              patch_size=256,\n",
    "              num_classes=2,\n",
    "              convert_to_cat=True):\n",
    "    \"\"\"Generator function to yield image and mask tuples,\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_samples: DataFrame\n",
    "                   Subsetted dataframe as obtained from get_all_patches_from_slide\n",
    "    patch_size: int\n",
    "                Patch size\n",
    "    convert_to_cat: bool\n",
    "                    Should convert to categorical\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: tensor\n",
    "    Y: tensor\n",
    "\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    for _, batch_sample in batch_samples.iterrows():\n",
    "        slide_contains_tumor = batch_sample['uid'].startswith('tumor')\n",
    "\n",
    "        with WSIReader(batch_sample.slide_path, 40) as slide:\n",
    "            tiles = DeepZoomGenerator(\n",
    "                slide, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "            tile_loc = batch_sample.tile_loc  #[::-1]\n",
    "            if isinstance(tile_loc, six.string_types):\n",
    "                tile_row, tile_col = eval(tile_loc)\n",
    "            else:\n",
    "                tile_row, tile_col = tile_loc\n",
    "            # the get_tile tuple required is (col, row)\n",
    "            img = tiles.get_tile(tiles.level_count - 1, (tile_col, tile_row))\n",
    "            (tile_x, tile_y), tile_level, _ = tiles.get_tile_coordinates(\n",
    "                tiles.level_count - 1, (tile_col, tile_row))\n",
    "\n",
    "        if slide_contains_tumor:\n",
    "            json_filepath = batch_sample['json_filepath']\n",
    "            polygons = get_annotation_polygons(json_filepath, 'shapely')\n",
    "            mask = create_tumor_mask_from_tile(tile_x, tile_y, polygons,\n",
    "                                               patch_size)\n",
    "        else:\n",
    "            mask = np.zeros((patch_size, patch_size))\n",
    "\n",
    "        images.append(np.array(img))\n",
    "        masks.append(mask)\n",
    "\n",
    "    X_train = np.array(images)\n",
    "    y_train = np.array(masks)\n",
    "    if convert_to_cat:\n",
    "        y_train = mask_to_categorical(y_train, num_classes, patch_size)\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_path = '/Z/personal-folders/interns/saket/histopath_data/CAMELYON16/training/tumor/tumor_009.tif'\n",
    "json_filepath = '/Z/personal-folders/interns/saket/histopath_data/CAMELYON16/training/lesion_annotations_json/tumor_009.json'\n",
    "#all_samples = get_all_patches_from_slide(slide_path, json_filepath, False,\n",
    "#                                         256)\n",
    "#all_samples = all_samples.sample(frac=0.001)\n",
    "\n",
    "all_samples = pd.read_table('/Z/personal-folders/interns/saket/github/pyvirchow/data/patch_df/validate_df_with_mask.tsv')\n",
    "all_samples = all_samples.sample(frac=0.001)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.load_weights('weights-improvement-12-0.98.hdf')\n",
    "\n",
    "\n",
    "all_samples[['row', 'col']] = all_samples.tile_loc.astype(tuple).str.replace(' ','').str.replace(')', '').str.replace('(', '').str.split(',', expand=True)\n",
    "#all_samples.uid.cat(x[:,0], sep='_')\n",
    "all_samples['img_path1'] = all_samples[['uid', 'row', 'col']].apply(lambda x: '_'.join(x.values.tolist()),\n",
    "                                                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21602    xnormal_159_276_153\n",
       "20847     xtumor_046_267_164\n",
       "10533     xtumor_046_314_177\n",
       "43582       xtumor_097_66_91\n",
       "26114     xtumor_046_258_126\n",
       "50057     xtumor_011_407_170\n",
       "24141     xtumor_069_296_187\n",
       "39599     xtumor_085_223_257\n",
       "34447     xtumor_085_180_138\n",
       "9064     xnormal_130_237_198\n",
       "23498     xtumor_085_201_245\n",
       "26938     xtumor_011_443_279\n",
       "9339      xtumor_046_275_203\n",
       "34180     xtumor_065_396_188\n",
       "16765     xtumor_031_649_222\n",
       "49023     xtumor_046_279_177\n",
       "52955     xtumor_085_188_266\n",
       "32544     xtumor_011_435_313\n",
       "19005     xtumor_046_276_196\n",
       "6347     xnormal_097_522_123\n",
       "2602       xtumor_097_96_448\n",
       "56518     xtumor_085_181_289\n",
       "18066    xnormal_097_538_296\n",
       "14999     xtumor_046_202_186\n",
       "37070     xtumor_011_439_242\n",
       "25627      xtumor_005_668_98\n",
       "44215     xtumor_069_399_302\n",
       "10268      xtumor_085_97_154\n",
       "7252     xnormal_092_345_153\n",
       "51185     xtumor_046_385_172\n",
       "32728     xtumor_085_210_260\n",
       "9509     xnormal_092_297_229\n",
       "29813     xtumor_046_249_172\n",
       "52325     xtumor_011_617_249\n",
       "860       xtumor_011_440_235\n",
       "8554     xnormal_142_375_197\n",
       "5425      xnormal_020_39_365\n",
       "17940     xtumor_046_306_156\n",
       "21765     xtumor_011_463_144\n",
       "36945     xtumor_085_212_247\n",
       "8747      xtumor_046_360_206\n",
       "49623    xnormal_097_312_198\n",
       "3358      xtumor_046_201_185\n",
       "13388    xnormal_142_128_173\n",
       "50486      xtumor_046_293_68\n",
       "40532     xtumor_069_333_207\n",
       "45075    xnormal_159_244_295\n",
       "51180     xtumor_005_535_209\n",
       "13873     xtumor_046_312_226\n",
       "9369     xnormal_092_374_265\n",
       "39311     xtumor_065_388_223\n",
       "8016     xnormal_100_497_286\n",
       "53090    xnormal_130_175_140\n",
       "27281    xnormal_130_305_244\n",
       "43407     xtumor_085_186_150\n",
       "14728    xnormal_136_132_148\n",
       "17130      xtumor_011_66_157\n",
       "Name: img_path1, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'x' + all_samples['img_path1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33801</th>\n",
       "      <td>263</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35249</th>\n",
       "      <td>134</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39456</th>\n",
       "      <td>324</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30882</th>\n",
       "      <td>296</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54382</th>\n",
       "      <td>654</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>335</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>448</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31927</th>\n",
       "      <td>411</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45847</th>\n",
       "      <td>405</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56606</th>\n",
       "      <td>631</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>213</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>26</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21367</th>\n",
       "      <td>585</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16802</th>\n",
       "      <td>648</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30858</th>\n",
       "      <td>241</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33143</th>\n",
       "      <td>34</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14863</th>\n",
       "      <td>579</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>638</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56187</th>\n",
       "      <td>68</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21423</th>\n",
       "      <td>445</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>255</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22443</th>\n",
       "      <td>365</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>326</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15107</th>\n",
       "      <td>833</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37575</th>\n",
       "      <td>77</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>212</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>347</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>400</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45332</th>\n",
       "      <td>466</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>264</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>293</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42957</th>\n",
       "      <td>123</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>469</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34822</th>\n",
       "      <td>53</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>57</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20932</th>\n",
       "      <td>310</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13308</th>\n",
       "      <td>332</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>638</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19267</th>\n",
       "      <td>218</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30809</th>\n",
       "      <td>416</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47242</th>\n",
       "      <td>546</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>370</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>213</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31800</th>\n",
       "      <td>177</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23521</th>\n",
       "      <td>584</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12461</th>\n",
       "      <td>435</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>181</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36412</th>\n",
       "      <td>268</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>401</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43638</th>\n",
       "      <td>112</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25356</th>\n",
       "      <td>82</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20792</th>\n",
       "      <td>195</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53763</th>\n",
       "      <td>591</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43654</th>\n",
       "      <td>235</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37726</th>\n",
       "      <td>319</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15048</th>\n",
       "      <td>263</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53075</th>\n",
       "      <td>852</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "33801  263   210\n",
       "35249  134   122\n",
       "39456  324   225\n",
       "30882  296   262\n",
       "54382  654   246\n",
       "56911  335   240\n",
       "4793   448   216\n",
       "31927  411   219\n",
       "45847  405   274\n",
       "56606  631   247\n",
       "791    213   125\n",
       "4691    26   349\n",
       "21367  585   264\n",
       "16802  648   189\n",
       "30858  241   147\n",
       "33143   34   135\n",
       "14863  579   213\n",
       "4961   638   209\n",
       "56187   68   443\n",
       "21423  445   163\n",
       "7992   255   135\n",
       "22443  365   224\n",
       "1039   326   219\n",
       "15107  833   323\n",
       "37575   77   391\n",
       "7378   212   398\n",
       "5974   347   196\n",
       "8885   400   175\n",
       "45332  466   213\n",
       "4171   264   147\n",
       "5916   293   166\n",
       "42957  123    92\n",
       "3175   469   300\n",
       "34822   53   389\n",
       "11731   57    87\n",
       "20932  310   131\n",
       "13308  332   164\n",
       "15919  638   114\n",
       "19267  218   252\n",
       "30809  416   254\n",
       "47242  546   154\n",
       "7522   370   198\n",
       "23468  213   248\n",
       "31800  177   136\n",
       "23521  584   280\n",
       "12461  435   211\n",
       "5822   181   256\n",
       "36412  268   184\n",
       "11820  401   207\n",
       "43638  112   115\n",
       "25356   82   163\n",
       "20792  195   179\n",
       "53763  591   169\n",
       "43654  235   299\n",
       "37726  319   135\n",
       "15048  263   235\n",
       "53075  852   172"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(263, 210)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(134, 122)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(324, 225)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(296, 262)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(654, 246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(335, 240)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(448, 216)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(411, 219)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(405, 274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(631, 247)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(213, 125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(26, 349)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(585, 264)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(648, 189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(241, 147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(34, 135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(579, 213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(638, 209)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(68, 443)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(445, 163)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(255, 135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(365, 224)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(326, 219)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(833, 323)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(77, 391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(212, 398)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(347, 196)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(400, 175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(466, 213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(264, 147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(293, 166)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(123, 92)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(469, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(53, 389)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(57, 87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(310, 131)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(332, 164)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(638, 114)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(218, 252)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(416, 254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(546, 154)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(370, 198)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(213, 248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(177, 136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(584, 280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(435, 211)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(181, 256)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(268, 184)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>(401, 207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(112, 115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>(82, 163)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(195, 179)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>(591, 169)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>(235, 299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>(319, 135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>(263, 235)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>(852, 172)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0   (263, 210)\n",
       "1   (134, 122)\n",
       "2   (324, 225)\n",
       "3   (296, 262)\n",
       "4   (654, 246)\n",
       "5   (335, 240)\n",
       "6   (448, 216)\n",
       "7   (411, 219)\n",
       "8   (405, 274)\n",
       "9   (631, 247)\n",
       "10  (213, 125)\n",
       "11   (26, 349)\n",
       "12  (585, 264)\n",
       "13  (648, 189)\n",
       "14  (241, 147)\n",
       "15   (34, 135)\n",
       "16  (579, 213)\n",
       "17  (638, 209)\n",
       "18   (68, 443)\n",
       "19  (445, 163)\n",
       "20  (255, 135)\n",
       "21  (365, 224)\n",
       "22  (326, 219)\n",
       "23  (833, 323)\n",
       "24   (77, 391)\n",
       "25  (212, 398)\n",
       "26  (347, 196)\n",
       "27  (400, 175)\n",
       "28  (466, 213)\n",
       "29  (264, 147)\n",
       "30  (293, 166)\n",
       "31   (123, 92)\n",
       "32  (469, 300)\n",
       "33   (53, 389)\n",
       "34    (57, 87)\n",
       "35  (310, 131)\n",
       "36  (332, 164)\n",
       "37  (638, 114)\n",
       "38  (218, 252)\n",
       "39  (416, 254)\n",
       "40  (546, 154)\n",
       "41  (370, 198)\n",
       "42  (213, 248)\n",
       "43  (177, 136)\n",
       "44  (584, 280)\n",
       "45  (435, 211)\n",
       "46  (181, 256)\n",
       "47  (268, 184)\n",
       "48  (401, 207)\n",
       "49  (112, 115)\n",
       "50   (82, 163)\n",
       "51  (195, 179)\n",
       "52  (591, 169)\n",
       "53  (235, 299)\n",
       "54  (319, 135)\n",
       "55  (263, 235)\n",
       "56  (852, 172)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_samples.tile_loc.apply(pd.Series)\n",
    "pd.DataFrame(all_samples.tile_loc.astype(tuple).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_thumbnails = slide_level_map(slide_path=slide_path, batch_size=32, \n",
    "#                                       json_filepath=json_filepath, model=model)\n",
    "def process_batch(args):\n",
    "    idx, model, batch_samples, batch_size = args\n",
    "    output_thumbnail_pred = None\n",
    "    X, _ = get_tiles(batch_samples)\n",
    "    X, _ = get_tiles_fast(batch_samples)\n",
    "\n",
    "    if batch_samples.is_tissue.nunique(\n",
    "    ) == 1 and batch_samples.iloc[0].is_tissue == False:\n",
    "        # all patches in this row do not have tissue, skip them all\n",
    "        output_thumbnail_pred = np.zeros(batch_size, dtype=np.float32)\n",
    "\n",
    "    else:\n",
    "        # make predictions\n",
    "        preds = predict_on_batch(X, model)\n",
    "        output_thumbnail_pred = preds.mean(axis=(1, 2))\n",
    "    return idx, output_thumbnail_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 8.24149 s\n",
       "File: <ipython-input-40-1c5752ab191d>\n",
       "Function: process_batch at line 3\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     3                                           def process_batch(args):\n",
       "     4         1          6.0      6.0      0.0      idx, model, batch_samples, batch_size = args\n",
       "     5         1          3.0      3.0      0.0      output_thumbnail_pred = None\n",
       "     6         1    7059359.0 7059359.0     85.7      X, _ = get_tiles(batch_samples)\n",
       "     7         1     113903.0 113903.0      1.4      X, _ = get_tiles_fast(batch_samples)\n",
       "     8                                           \n",
       "     9         1        354.0    354.0      0.0      if batch_samples.is_tissue.nunique(\n",
       "    10         1        609.0    609.0      0.0      ) == 1 and batch_samples.iloc[0].is_tissue == False:\n",
       "    11                                                   # all patches in this row do not have tissue, skip them all\n",
       "    12                                                   output_thumbnail_pred = np.zeros(batch_size, dtype=np.float32)\n",
       "    13                                           \n",
       "    14                                               else:\n",
       "    15                                                   # make predictions\n",
       "    16         1    1064802.0 1064802.0     12.9          preds = predict_on_batch(X, model)\n",
       "    17         1       2451.0   2451.0      0.0          output_thumbnail_pred = preds.mean(axis=(1, 2))\n",
       "    18         1          2.0      2.0      0.0      return idx, output_thumbnail_pred"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f process_batch process_batch((0, model, all_samples, len(all_samples.index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_samples.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/102 [00:03<06:01,  3.58s/it]\u001b[A\n",
      "  2%|▏         | 2/102 [00:07<06:14,  3.74s/it]\u001b[A\n",
      "  3%|▎         | 3/102 [00:12<06:49,  4.14s/it]\u001b[A\n",
      "  4%|▍         | 4/102 [00:17<07:04,  4.33s/it]\u001b[A\n",
      "  5%|▍         | 5/102 [00:22<07:18,  4.52s/it]\u001b[A\n",
      "  6%|▌         | 6/102 [00:27<07:21,  4.59s/it]\u001b[A\n",
      "  7%|▋         | 7/102 [00:32<07:18,  4.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 44.6272 s\n",
       "File: <ipython-input-27-055c5ecb65c0>\n",
       "Function: slide_level_map at line 317\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   317                                           def slide_level_map(model, slide_path, batch_size=32, json_filepath=None):\n",
       "   318         1          3.0      3.0      0.0      all_samples = get_all_patches_from_slide(slide_path, json_filepath, False,\n",
       "   319         1    1716894.0 1716894.0      3.8                                               256)\n",
       "   320         1      46393.0  46393.0      0.1      all_samples = all_samples.sample(frac=0.01)\n",
       "   321         1         22.0     22.0      0.0      n_samples = len(all_samples.index)\n",
       "   322         1          1.0      1.0      0.0      all_batch_samples = []\n",
       "   323       103        209.0      2.0      0.0      for idx, offset in enumerate(list(range(0, n_samples, batch_size))):\n",
       "   324       102      41970.0    411.5      0.1          all_batch_samples.append((idx , model, all_samples.iloc[offset:offset + batch_size], batch_size))\n",
       "   325         1          1.0      1.0      0.0      output_thumbnail_preds = []\n",
       "   326         1          1.0      1.0      0.0      output_thumbnail_idx = []\n",
       "   327         1          2.0      2.0      0.0      total = len(all_batch_samples)\n",
       "   328         1    5787964.0 5787964.0     13.0      idx, o = process_batch(all_batch_samples[0])\n",
       "   329                                               #print(idx)\n",
       "   330                                               #print(o)\n",
       "   331                                               #with Pool(processes=32) as p:\n",
       "   332                                               #    with tqdm(total=total) as pbar:\n",
       "   333                                               #for idx, result in (process_batch, all_batch_samples):\n",
       "   334         8      26151.0   3268.9      0.1      for batch in tqdm(all_batch_samples):\n",
       "   335         8   37007545.0 4625943.1     82.9          idx, result = process_batch(batch)\n",
       "   336         7         45.0      6.4      0.0          output_thumbnail_preds.append(result)\n",
       "   337         7         10.0      1.4      0.0          output_thumbnail_idx.append(idx)\n",
       "   338                                                   #pbar.update()\n",
       "   339                                               output_thumbnail_idx = np.array(output_thumbnail_idx)\n",
       "   340                                               output_thumbnail_preds = np.array(output_thumbnail_preds)\n",
       "   341                                               output_thumbnail_preds = output_thumbnail_preds[output_thumbnail_idx]\n",
       "   342                                               return output_thumbnail_preds"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f slide_level_map slide_level_map(slide_path=slide_path, batch_size=32, json_filepath=json_filepath, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
